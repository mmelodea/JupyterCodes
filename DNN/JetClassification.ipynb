{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "#set adequate flag for Theano\n",
    "import theano\n",
    "theano.config.gcc.cxxflags = '-march=corei7'\n",
    "#load needed things\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.layers import Input, Activation, Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import interp\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as pyp\n",
    "import itertools\n",
    "import math\n",
    "import ROOT\n",
    "import cPickle as pickle\n",
    "from UserFunctions import *\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load events\n",
    "filein = open('hzz4l_vbf_selection_noDjet_m4l118-130GeV_shuffledFS_JetExtraInfo.pkl','r')\n",
    "events = pickle.load( filein )\n",
    "filein.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, scales = prepareJetComponents(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare inputs for model\n",
    "split_factor = 0.8\n",
    "X_train = []\n",
    "Y_train = []\n",
    "sc_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "sc_test = []\n",
    "\n",
    "for ik in events:\n",
    "    for iev in range(len(events[ik])):\n",
    "        if iev < int(split_factor*len(events[ik])):\n",
    "            for ijet in range(1):#len(events[ik][iev])):\n",
    "                sc_train.append( scales[ik] )\n",
    "                X_train.append( events[ik][iev][ijet] )\n",
    "                if ik == 'VBF':\n",
    "                    Y_train.append( 1 )\n",
    "                else:\n",
    "                    Y_train.append( 0 )\n",
    "        else:\n",
    "            for ijet in range(1):#len(events[ik][iev])):\n",
    "                sc_test.append( scales[ik] )\n",
    "                X_test.append( events[ik][iev][ijet] )\n",
    "                if ik == 'VBF':\n",
    "                    Y_test.append( 1 )\n",
    "                else:\n",
    "                    Y_test.append( 0 )\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "sc_train = np.asarray(sc_train)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)\n",
    "sc_test = np.asarray(sc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatable plot\n",
    "from IPython.display import clear_output\n",
    "class Tscheduler(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = []\n",
    "        self.val_accs = []\n",
    "        self.logs = []\n",
    "        self.trocs = []\n",
    "        self.vrocs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.val_accs.append(logs.get('val_acc'))\n",
    "        Y_score = dnn_model.predict(X_train)\n",
    "        fpr, tpr, thresholds = roc_curve(Y_train, Y_score, sample_weight=sc_train)\n",
    "        roc_auc = auc(fpr, tpr, reorder=True)\n",
    "        self.trocs.append(roc_auc)\n",
    "        Y_score = dnn_model.predict(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test, Y_score, sample_weight=sc_test)\n",
    "        roc_auc = auc(fpr, tpr, reorder=True)\n",
    "        self.vrocs.append(roc_auc)\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        fig = pyp.figure()\n",
    "        fig.set_figheight(6)\n",
    "        fig.set_figwidth(13)\n",
    "        \n",
    "        fig1 = fig.add_subplot(121)\n",
    "        pyp.plot(self.x, self.losses, label=\"tloss: %f\" % self.losses[len(self.losses)-1]) \n",
    "        pyp.plot(self.x, self.val_losses, label=\"vloss: %f\" % self.val_losses[len(self.val_losses)-1])\n",
    "        #pyp.plot(self.x, self.accs, label=\"tacc: %f\" % self.accs[len(self.accs)-1]) \n",
    "        #pyp.plot(self.x, self.val_accs, label=\"vacc: %f\" % self.val_accs[len(self.val_accs)-1])\n",
    "        #c_lrate = K.eval(self.model.optimizer.lr)\n",
    "        #pyp.title(\"Current LR: %f\" % c_lrate)\n",
    "        #c_momentum = K.eval(self.model.optimizer.momentum)\n",
    "        #pyp.title(\"Current M: %f\" % c_momentum)\n",
    "        pyp.xlabel('epochs')\n",
    "        pyp.ylabel('Loss')\n",
    "        pyp.legend()\n",
    "        #pyp.ylim([0.7,1.2])\n",
    "        pyp.grid(True)\n",
    "        #pyp.show()\n",
    "        \n",
    "        fig2 = fig.add_subplot(122)\n",
    "        pyp.plot(self.x, self.trocs, color='blue', label='Current train AUC = %0.3f' % self.trocs[len(self.trocs)-1])\n",
    "        pyp.plot(self.x, self.vrocs, color='red', label='Current   test AUC = %0.3f' % self.vrocs[len(self.vrocs)-1])\n",
    "        #pyp.ylim([0, 1.0])\n",
    "        pyp.xlabel('epochs')\n",
    "        pyp.ylabel('AUC')\n",
    "        pyp.title('ROC evolution')\n",
    "        pyp.legend()\n",
    "        pyp.grid(True)\n",
    "        #pyp.show()\n",
    "\n",
    "        pyp.tight_layout()\n",
    "        fig = pyp.show()\n",
    "\n",
    "        #changing lr based on loss\n",
    "        #if(len(self.losses) > 20):\n",
    "        #    lsum1 = 0\n",
    "        #    lsum2 = 0\n",
    "        #    for i in range(6):\n",
    "        #        if(i < 3):\n",
    "        #            lsum1 += self.losses[len(self.losses)-1-i]/3.\n",
    "        #        else:\n",
    "        #            lsum2 += self.losses[len(self.losses)-1-i]/3.\n",
    "        #    if(math.fabs(lsum2-lsum1) < 0.01):\n",
    "        #        n_lrate = c_lrate*(1 - 1/20.)\n",
    "        #        K.set_value(self.model.optimizer.lr, n_lrate)\n",
    "        #else:\n",
    "        #    n_lrate = self.losses[len(self.losses)-1]*0.001\n",
    "        #    K.set_value(self.model.optimizer.lr, n_lrate)\n",
    "        \n",
    "        #initial_lrate = 0.001\n",
    "        #drop = 0.6\n",
    "        #epochs_drop = 100\n",
    "        #lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "        #K.set_value(self.model.optimizer.lr, 0.001)\n",
    "        \n",
    "        #stop training if training and testing Loss get too away\n",
    "        #if(epoch > 50):\n",
    "        #    train_sum = 0\n",
    "        #    val_sum = 0\n",
    "        #    for i in range(30):\n",
    "        #        train_sum += self.losses[len(self.losses)-1-i]/6.\n",
    "        #        val_sum += self.val_losses[len(self.val_losses)-1-i]/6.\n",
    "        #    if(train_sum-val_sum < -0.02):\n",
    "        #        self.model.stop_training = True\n",
    "        #        print \"Stoping training!\"\n",
    "                \n",
    "            \n",
    "Tschedule = Tscheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for training\n",
    "nepochs = 20\n",
    "wait_for = 60\n",
    "sbatch = 128\n",
    "opt = Adam()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=wait_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- DNN Topology --------- \n",
      "Inputs: 300\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 38,021\n",
      "Trainable params: 38,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#DNN network\n",
    "ninputs = len(X_train[0])\n",
    "print \"---------- DNN Topology --------- \"\n",
    "print \"Inputs: %i\" % ninputs\n",
    "\n",
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(100, input_shape=(ninputs,), activation='relu', kernel_initializer='random_uniform'))\n",
    "dnn_model.add(Dense(60, activation='relu', kernel_initializer='random_uniform'))    \n",
    "dnn_model.add(Dense(30, activation='relu', kernel_initializer='random_uniform'))    \n",
    "dnn_model.add(Dense(1, activation='sigmoid', kernel_initializer='random_uniform'))    \n",
    "dnn_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63828 samples, validate on 15959 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 1.3700 - acc: 0.5508 - val_loss: 1.3659 - val_acc: 0.5808\n",
      "Epoch 2/20\n",
      "3s - loss: 1.3370 - acc: 0.5738 - val_loss: 1.3429 - val_acc: 0.5780\n",
      "Epoch 3/20\n",
      "3s - loss: 1.3279 - acc: 0.5849 - val_loss: 1.3367 - val_acc: 0.5906\n",
      "Epoch 4/20\n",
      "3s - loss: 1.3229 - acc: 0.5874 - val_loss: 1.3360 - val_acc: 0.5995\n",
      "Epoch 5/20\n",
      "3s - loss: 1.3178 - acc: 0.5912 - val_loss: 1.3408 - val_acc: 0.6025\n",
      "Epoch 6/20\n",
      "3s - loss: 1.3112 - acc: 0.5957 - val_loss: 1.3329 - val_acc: 0.6013\n",
      "Epoch 7/20\n",
      "4s - loss: 1.3096 - acc: 0.5959 - val_loss: 1.3276 - val_acc: 0.5950\n",
      "Epoch 8/20\n",
      "4s - loss: 1.3055 - acc: 0.5963 - val_loss: 1.3427 - val_acc: 0.5943\n",
      "Epoch 9/20\n",
      "4s - loss: 1.3020 - acc: 0.5973 - val_loss: 1.3282 - val_acc: 0.5852\n",
      "Epoch 10/20\n",
      "4s - loss: 1.2988 - acc: 0.5985 - val_loss: 1.3328 - val_acc: 0.6010\n",
      "Epoch 11/20\n",
      "4s - loss: 1.2964 - acc: 0.5985 - val_loss: 1.3356 - val_acc: 0.5910\n",
      "Epoch 12/20\n",
      "4s - loss: 1.2933 - acc: 0.6020 - val_loss: 1.3306 - val_acc: 0.5671\n",
      "Epoch 13/20\n",
      "4s - loss: 1.2924 - acc: 0.5978 - val_loss: 1.3329 - val_acc: 0.5724\n",
      "Epoch 14/20\n",
      "4s - loss: 1.2901 - acc: 0.6019 - val_loss: 1.3308 - val_acc: 0.5794\n",
      "Epoch 15/20\n",
      "4s - loss: 1.2859 - acc: 0.6003 - val_loss: 1.3342 - val_acc: 0.5933\n",
      "Epoch 16/20\n",
      "4s - loss: 1.2844 - acc: 0.6051 - val_loss: 1.3369 - val_acc: 0.5927\n",
      "Epoch 17/20\n",
      "4s - loss: 1.2824 - acc: 0.6047 - val_loss: 1.3395 - val_acc: 0.5998\n",
      "Epoch 18/20\n",
      "4s - loss: 1.2801 - acc: 0.6044 - val_loss: 1.3344 - val_acc: 0.5726\n",
      "Epoch 19/20\n",
      "4s - loss: 1.2781 - acc: 0.6045 - val_loss: 1.3457 - val_acc: 0.5795\n",
      "Epoch 20/20\n",
      "4s - loss: 1.2773 - acc: 0.6023 - val_loss: 1.3432 - val_acc: 0.6035\n"
     ]
    }
   ],
   "source": [
    "#filepath1=\"best_weights.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath1, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "#train the DNN\n",
    "history1 = dnn_model.fit(X_train,\n",
    "                        Y_train, \n",
    "                        sample_weight=sc_train,\n",
    "                        validation_data=(X_test,\n",
    "                                         Y_test\n",
    "                                         ,sc_test\n",
    "                                        ), \n",
    "                        epochs=nepochs,\n",
    "                        batch_size=sbatch, \n",
    "                        verbose=2,\n",
    "                        callbacks=[early_stopping]#,Tschedule]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
